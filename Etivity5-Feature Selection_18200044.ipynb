{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds on top of Lab 4 by introducing feature selection into the process of selecting the best classifier for a binary classification problem.\n",
    "\n",
    "The feature selection method applied here is Recursive Feature Elimination (RFE) as demonstrated in the tutorial at https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/.\n",
    "\n",
    "In this demonstration we use a modified version of the seeds data set (see https://archive.ics.uci.edu/ml/datasets/seeds), which is the same data set used in Lab 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing #needed for scaling attributes to the interval [0,1]\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif, SelectPercentile, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the dataset for training and evaluation\n",
    "Feel free to apply any other pre-processing technique at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab5_df = pd.read_csv(\"./winequality_red.csv\")\n",
    "lab5_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    681\n",
       "6    638\n",
       "7    199\n",
       "4     53\n",
       "8     18\n",
       "3     10\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab5_df['quality'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target attribute\n",
    "target_attribute_name = 'quality'\n",
    "target = lab5_df[target_attribute_name]\n",
    "\n",
    "# predictor attributes\n",
    "predictors = lab5_df.drop(target_attribute_name, axis=1).values\n",
    "\n",
    "# scale all predictor values to the range [0, 1]\n",
    "# the target is in a multiclass type\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "predictors = min_max_scaler.fit_transform(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a training (80%) and test (20%) data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pepare independent stratified data sets for training and test of the final model\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(\n",
    "    predictors, target, test_size=0.20, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Apply RFE with SVM for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False  True  True]\n",
      "[3 1 9 5 2 8 6 4 7 1 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorSVM = svm.SVR(kernel=\"linear\")\n",
    "selectorSVM = RFE(estimatorSVM, 3)\n",
    "selectorSVM = selectorSVM.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorSVM.support_)\n",
    "print(selectorSVM.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Apply RFE with Logistic Regression for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False  True False False False  True]\n",
      "[6 1 4 7 8 9 1 3 5 2 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorLR = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "selectorLR = RFE(estimatorLR, 3)\n",
    "selectorLR = selectorLR.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorLR.support_)\n",
    "print(selectorLR.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Evaluate on the Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selectors to prepare training data sets only with the selected features\n",
    "\n",
    "__Note:__ The same selectors are applied to the test data set. However, it is important that the test data set was not used by (it's invisible to) the selectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_SVMselected = selectorSVM.transform(predictors_train)\n",
    "predictors_test_SVMselected = selectorSVM.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_LRselected = selectorLR.transform(predictors_train)\n",
    "predictors_test_LRselected = selectorLR.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate SVM classifiers with both the selected features and all features \n",
    "\n",
    "Here we train three models:\n",
    "* model1 - with the features selected by SVM\n",
    "* model2 - with the features selected by Logistic Regression\n",
    "* model3 - with all features (i.e. without feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC()\n",
    "#decision_function_shape ='ovr' is used by default::one-vs-rest= each class is predicted against the remaining classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.553125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = classifier.fit(predictors_train_SVMselected, target_train)\n",
    "model1.score(predictors_test_SVMselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = classifier.fit(predictors_train_LRselected, target_train)\n",
    "model2.score(predictors_test_LRselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56875"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = classifier.fit(predictors_train, target_train,)\n",
    "#model3.score(predictors_test, target_test, gamma = auto)\n",
    "model3.score(predictors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Conclusion\n",
    "\n",
    "We conclude that none of the three models gives good result. Indeed all scores are under 60% accuracy. However the use of predictors selected by Logistic Regression RFE gives best result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEZNJREFUeJzt3X+MZedd3/H3Z3dZedNVSBwvievxslZnrYKQS8jI0KYE18hgoNhq3SbmR2ErpS5Cq2mpWslbRaY1RuJX1XYaS7AJFg7Q2GrUhrWzxDEpbgXCdMes67BrnLm4iX1tN9l4Y8iy/sF6v/1j7qo3N2PNnZ07e/bO835JV3POc57znO+ZY3/us2fuj1QVkqQ2bOm6AEnShWPoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhqyresCRl122WW1Z8+ersuQpKny2GOPfamqdq3W76IL/T179rC4uNh1GZI0VZJ8fpx+3t6RpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhF93r9KX1WlhYoNfrTXzcfr8PwMzMzMTHnp2dZX5+fuLjSqMMfWlML7/8ctclSOtm6GvT2agZ87lxFxYWNmR86ULwnr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JashYoZ/kxiRPJekluf0N+rw3yfEkx5L856H2H0+yNHj8+KQKlySt3aqfp59kK3A3cAPQB44kOVRVx4f67AUOAO+uqi8n+YZB+6XATwNzQAGPDfb98uRPRZK0mnFm+tcCvap6uqpeA+4Dbh7p80+Au8+FeVV9cdD+vcDDVXVysO1h4MbJlC5JWqtxQv8K4Nmh9f6gbdjVwNVJfj/Jo0luXMO+JLktyWKSxRMnToxfvSRpTcYJ/azQViPr24C9wHXADwEfTvKWMfelqg5W1VxVze3atWuMkiRJ52Oc0O8DVw6tzwDPr9Dnt6rqL6vq/wBPsfwkMM6+kqQLZJzQPwLsTXJVku3ArcChkT4fB/4OQJLLWL7d8zTwEPA9Sd6a5K3A9wzaJEkdWPXVO1V1Jsl+lsN6K3BPVR1LciewWFWH+P/hfhx4HfhXVfUiQJKfYfmJA+DOqjq5ESciSVrdqqEPUFWHgcMjbXcMLRfwLwaP0X3vAe5ZX5mSpEkYK/Ql6UJYWFig1+tNfNx+vw/AzMzMxMcGmJ2dZX5+fkPGnjRDX9Km9/LLL3ddwkXD0Jd00dio2fK5cRcWFjZk/GniB65JUkMMfUlqiKEvSQ3xnv4KfAWBpM3K0L+AfAWBpK4Z+ivwFQSSNivv6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkG3jdEpyI/Afga3Ah6vq50a27wN+EXhu0PTBqvrwYNsvAD/A8hPMw8A/q6qaSPWSOrGwsECv1+u6jLEtLS0BMD8/33ElazM7OzvxmlcN/SRbgbuBG4A+cCTJoao6PtL1/qraP7Lv3wLeDVwzaPo94LuAR9ZZt6bctIUGTGdwbERoAPR6PY4eOwpvmfjQG+Ps8o+jzx3tto61eGljhh1npn8t0KuqpwGS3AfcDIyG/koKuATYDgT4OuAL51eqNpNer8dn//iP2L3z9a5LGdv2v1y+G/rK5450XMl4njm1dWMP8BY4e93ZjT1Gw7Y8sjF338cJ/SuAZ4fW+8C3r9DvliTvAT4L/FRVPVtVf5Dkd4EXWA79D1bVk6M7JrkNuA1g9+7dazwFTavdO1/nA3Onui5j07prcWfXJegiNM5TSVZoG70n/wCwp6quAX4HuBcgySzwTcAMy08e1w+eGL56sKqDVTVXVXO7du1aS/2SpDUYJ/T7wJVD6zPA88MdqurFqnp1sPoh4F2D5b8HPFpVp6rqFPDbwHesr2RJ0vkaJ/SPAHuTXJVkO3ArcGi4Q5LLh1ZvAs7dwnkG+K4k25J8Hct/xP2a2zuSpAtj1Xv6VXUmyX7gIZZfsnlPVR1LciewWFWHgPkkNwFngJPAvsHuHwOuBz7D8i2hT1bVA5M/DUnSOMZ6nX5VHQYOj7TdMbR8ADiwwn6vA/90nTVKkibEd+RKUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoy1peoXKwWFhbo9XpdlzG2paUlAObn5zuuZG1mZ2enrmZtrH6/D38GWx5x3rhhXoJ+9Sc+7FSHfq/X4+hnjnP2TZd2XcpY8loB8Nif/t+OKxnfltMnuy5B0gRNdegDnH3TpbzyzX+36zI2rUuOP9h1CboIzczMcCInOHvd2a5L2bS2PLKFmStmJj/uxEeUJF20DH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkKl/nb6mU7/f5y++spW7Fnd2Xcqm9fmvbOWv9Cf/jk5NN2f6ktQQZ/rqxMzMDK+ceYEPzJ3qupRN667FnVwyM/l3dGq6OdOXpIYY+pLUkLFCP8mNSZ5K0kty+wrb9yU5keTxweP9Q9t2J/lUkieTHE+yZ3LlS5LWYtV7+km2AncDNwB94EiSQ1V1fKTr/VW1f4UhPgL8bFU9nGQn4MfySVJHxpnpXwv0qurpqnoNuA+4eZzBk3wzsK2qHgaoqlNVdfq8q5Ukrcs4oX8F8OzQen/QNuqWJE8k+ViSKwdtVwMvJfmvSY4m+cXBvxwkSR0Y5yWbWaGtRtYfAD5aVa8m+QngXuD6wfjfCbwTeAa4H9gH/OpXHSC5DbgNYPfu3WMX3+/32XL6z/yijw205fSL9Ptnui5D0oSMM9PvA1cOrc8Azw93qKoXq+rVweqHgHcN7Xt0cGvoDPBx4NtGD1BVB6tqrqrmdu3atdZzkCSNaZyZ/hFgb5KrgOeAW4EfHu6Q5PKqemGwehPw5NC+b02yq6pOsDz7X5xI5Sy/wecLr27z6xI30CXHH2Rm5h1dlyFpQlYN/ao6k2Q/8BCwFbinqo4luRNYrKpDwHySm4AzwEmWb+FQVa8n+ZfAp5MEeIzlfwlIkjow1scwVNVh4PBI2x1DyweAA2+w78PANeuoUZI0Ib4jV5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSFjfcqmJH2Nl2DLI1Mybzw1+Lmz0yrW5iVW/mLadTL01ZlnTm3lrsXp+b/wC6eXA+7tbzrbcSXjeebUVq7eoLFnZ2c3aOSNsbS0BMDeK/Z2XMkaXLExv2dDX52YttAAeG0QHJfsmY7guJqN+z3Pz89vyLgb5Vy9CwsLHVfSPUNfnZi20ACDQ5vDlNyQkyRNgqEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoyVugnuTHJU0l6SW5fYfu+JCeSPD54vH9k+5uTPJfkg5MqXJK0dqt+iUqSrcDdwA1AHziS5FBVHR/pen9V7X+DYX4G+B/rqlSStG7jfHPWtUCvqp4GSHIfcDMwGvorSvIu4O3AJ4G586zzDW05fZJLjj846WE3RF75cwDqkjd3XMn4tpw+Cbyj6zIkTcg4oX8F8OzQeh/49hX63ZLkPcBngZ+qqmeTbAH+HfCPgO9eb7Gjpu17VpeWvgLA3r82TSH6jqn7PUt6Y+OEflZoq5H1B4CPVtWrSX4CuBe4HvhJ4PDgCeCND5DcBtwGsHv37nHqBqbve1b9jlVJXRsn9PvAlUPrM8Dzwx2q6sWh1Q8BPz9Y/pvAdyb5SWAnsD3Jqaq6fWT/g8BBgLm5udEnFEnShIwT+keAvUmuAp4DbgV+eLhDksur6oXB6k3AkwBV9SNDffYBc6OBL0m6cFYN/ao6k2Q/8BCwFbinqo4luRNYrKpDwHySm4AzwElg3wbWLEk6T+PM9Kmqw8DhkbY7hpYPAAdWGePXgF9bc4WSpInxHbmS1BBDX5IaYuhLUkMMfUlqiKEvSQ0Z69U70jRZWFig1+tNfNylpSVgY94JPjs7O3XvMNd0MvSlMe3YsaPrEqR1M/S16Thjlt6Y9/QlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNGSv0k9yY5KkkvSS3r7B9X5ITSR4fPN4/aP/WJH+Q5FiSJ5K8b9InIEka37bVOiTZCtwN3AD0gSNJDlXV8ZGu91fV/pG208CPVdVSkr8KPJbkoap6aRLFS5LWZpyZ/rVAr6qerqrXgPuAm8cZvKo+W1VLg+XngS8Cu863WEnS+owT+lcAzw6t9wdto24Z3ML5WJIrRzcmuRbYDvzpeVUqSVq3cUI/K7TVyPoDwJ6qugb4HeDerxoguRz4deAfV9XZrzlAcluSxSSLJ06cGK9ySdKarXpPn+WZ/fDMfQZ4frhDVb04tPoh4OfPrSR5M/AJ4ANV9ehKB6iqg8BBgLm5udEnFEmNWFhYoNfrTXzcpaUlAObn5yc+NsDs7OyGjT1p48z0jwB7k1yVZDtwK3BouMNgJn/OTcCTg/btwH8DPlJV/2UyJUvS2uzYsYMdO3Z0XcZFYdWZflWdSbIfeAjYCtxTVceS3AksVtUhYD7JTcAZ4CSwb7D7e4H3AG9Lcq5tX1U9PtnTkLQZTMtseZqNc3uHqjoMHB5pu2No+QBwYIX9fgP4jXXWKEmaEN+RK0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDRnrHbmt8UOfJG1Whv4F5Ac+Seqaob8CZ8uSNivv6UtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IakqrquoavkuQE8Pmu69hAlwFf6roInTev3/Ta7NfuG6tq12qdLrrQ3+ySLFbVXNd16Px4/aaX126Zt3ckqSGGviQ1xNC/8A52XYDWxes3vbx2eE9fkpriTF+SGmLojyFJJfn1ofVtSU4keXCN43wuyWXn0yfJzyZ5NsmptRxT3V+/JG9K8okkf5LkWJKfW9sZtK3r6zdo/2SS/z24fr+cZOtajn0xMfTH8xfAtyQ599VXNwDPXeAaHgCuvcDH3Cwuhuv3S1X114F3Au9O8n0X+PjT7GK4fu+tqr8BfAuwC/iHF/j4E2Poj++3gR8YLP8Q8NFzG5JcmuTjSZ5I8miSawbtb0vyqSRHk/wKkKF9fjTJ/0ryeJJfWW3mUFWPVtULkz+tZnR2/arqdFX97mD5NeCPgJnJn+Km1vX/f38+WNwGbAem9o+hhv747gNuTXIJcA3wh0Pb/i1wtKquAf418JFB+08Dv1dV7wQOAbsBknwT8D7g3VX1rcDrwI9ckLNo10Vx/ZK8BfhB4NPrPqO2dH79kjwEfBH4CvCxSZxUF/yO3DFV1RNJ9rA8yzg8svlvA7cM+v33wQzj64H3AH9/0P6JJF8e9P9u4F3AkSQAO1j+j0kb5GK4fkm2sTxDXaiqp9d7Ti25GK5fVX3v4EnnN4HrgYfXeVqdMPTX5hDwS8B1wNuG2rNC3xr5OSzAvVV1YKLVaTVdX7+DwFJV/Yc17qdlXV8/quqVJIeAm5nS0Pf2ztrcA9xZVZ8Zaf+fDP55mOQ64EuDe4DD7d8HvHXQ/9PAP0jyDYNtlyb5xo0vv3mdXb8kdwFfD/zzyZxKkzq5fkl2Jrl8sLwN+H7gTyZ1UhdcVflY5QGcWqHtOuDBwfKlwG8BTwCPAtcM2t8GfIrlP9z9e5Y/PfSywbb3AY8P9nkM+I5B++fO9Rk53i8AfeDs4Oe/6fr3Mi2Prq8fy3+0LeDJwT6PA+/v+vcyLY+L4Pq9HTgy6HsM+E/Atq5/L+f78B25ktQQb+9IUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGvL/AOnjuTlFXhweAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def boxplots(n_iterations):\n",
    "    \n",
    "    score1=[]\n",
    "    score2=[]\n",
    "    score3=[]\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        # pepare independent stratified data sets for training and test of the final model\n",
    "        predictors_train, predictors_test, target_train, target_test = train_test_split(\n",
    "        predictors, target, test_size=0.20, shuffle=True, stratify=target)\n",
    "\n",
    "        # create a base classifier used to evaluate a subset of attributes (SVM)\n",
    "        estimatorSVM = svm.SVR(kernel=\"linear\")\n",
    "        selectorSVM = RFE(estimatorSVM, 3)\n",
    "        selectorSVM = selectorSVM.fit(predictors_train, target_train)\n",
    "\n",
    "\n",
    "        # create a base classifier used to evaluate a subset of attributes (LR)\n",
    "        estimatorLR = LogisticRegression()\n",
    "        selectorLR = RFE(estimatorLR, 3)\n",
    "        selectorLR = selectorLR.fit(predictors_train, target_train)\n",
    "\n",
    "        # Apply the selectors to prepare training and test data  sets only with the selected features\n",
    "        #SVM\n",
    "        predictors_train_SVMselected = selectorSVM.transform(predictors_train)\n",
    "        predictors_test_SVMselected = selectorSVM.transform(predictors_test)\n",
    "        #LR\n",
    "        predictors_train_LRselected = selectorLR.transform(predictors_train)\n",
    "        predictors_test_LRselected = selectorLR.transform(predictors_test)\n",
    "\n",
    "        #Train and evaluate SVM classifiers with both the selected features and all features\n",
    "        classifier = svm.SVC()\n",
    "\n",
    "        #Model1:with the features selected by SVM\n",
    "        model1 = classifier.fit(predictors_train_SVMselected, target_train)\n",
    "        score1=np.append(score1,model1.score(predictors_test_SVMselected, target_test))\n",
    "        #Model2:with the features selected by Logistic Regression\n",
    "        model2 = classifier.fit(predictors_train_LRselected, target_train)\n",
    "        score2=np.append(score2,model2.score(predictors_test_LRselected, target_test))\n",
    "        #Model3:with all features (i.e. without feature selection)\n",
    "        model3 = classifier.fit(predictors_train, target_train,)\n",
    "        score3=np.append(score3,model3.score(predictors_test, target_test))\n",
    "\n",
    "    #Create a dataframe with scores\n",
    "    Scores=pd.DataFrame([score1,score2,score3], index = ['Model 1' , 'Model 2', 'Model 3']) \n",
    "    #Boxplot\n",
    "    sns.boxplot(data=Scores.T)# Scores is transposed in order to get one column per model scores   \n",
    "    plt.show()  \n",
    "    \n",
    "boxplots(30)#Tries with different number of iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to Task 1 results, it seems that we are not getting better results since the maximum accuracy got from Model 3 is slightly above 60% not realy far from Task1 results. We also see that Model 2 like for Task1 is giving (in Median) better results. But we remark that Models 2 and 3 are getting best results than Model1 in most of the cases.\n",
    "One additional conclusion is about the variance of scores, even if model 2 is giving better results, it also presents a higher variance compared to Models 1 & 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset Predictiors in order to do the sclaing process inside the Pipelines\n",
    "predictors = lab5_df.drop(target_attribute_name, axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipe 1 Score is: 0.555347\n",
      "Pipe 1 Score is: 0.542214\n"
     ]
    }
   ],
   "source": [
    "anova_classif = SelectKBest(f_classif, k=5)\n",
    "selec_chi2 = SelectKBest(chi2, k=5)\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "\n",
    "Pipe1 = Pipeline([('scaler', preprocessing.MinMaxScaler()),('Anova', anova_classif), ('svc', clf)])\n",
    "Pipe2 = Pipeline([('scaler', preprocessing.MinMaxScaler()),('Chi2', selec_chi2), ('svc', clf)])\n",
    "\n",
    "# You can set the parameters using the names issued\n",
    "# For instance, fit using a k of 3 in the SelectKBest\n",
    "# and a parameter 'C' of the svm\n",
    "Pipe1.set_params(Anova__k=3, svc__C=.1).fit(predictors, target)\n",
    "#prediction = anova_svm.predict(X)\n",
    "print('Pipe 1 Score is: %f' %Pipe1.score(predictors, target) )\n",
    "\n",
    "Pipe2.set_params(Chi2__k=3, svc__C=.1).fit(predictors, target)\n",
    "print('Pipe 1 Score is: %f' %Pipe2.score(predictors, target)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
