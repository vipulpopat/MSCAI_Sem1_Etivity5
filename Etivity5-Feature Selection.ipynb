{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: Feature Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook builds on top of Lab 4 by introducing feature selection into the process of selecting the best classifier for a binary classification problem.\n",
    "\n",
    "The feature selection method applied here is Recursive Feature Elimination (RFE) as demonstrated in the tutorial at https://machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/.\n",
    "\n",
    "In this demonstration we use a modified version of the seeds data set (see https://archive.ics.uci.edu/ml/datasets/seeds), which is the same data set used in Lab 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing #needed for scaling attributes to the nterval [0,1]\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the dataset for training and evaluation\n",
    "Feel free to apply any other pre-processing technique at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>compactness</th>\n",
       "      <th>length of kernel</th>\n",
       "      <th>width of kernel</th>\n",
       "      <th>asymmetry coefficient</th>\n",
       "      <th>length of kernel groove</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>210.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.847524</td>\n",
       "      <td>14.559286</td>\n",
       "      <td>0.870999</td>\n",
       "      <td>5.628533</td>\n",
       "      <td>3.258605</td>\n",
       "      <td>3.700201</td>\n",
       "      <td>5.408071</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.909699</td>\n",
       "      <td>1.305959</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.443063</td>\n",
       "      <td>0.377714</td>\n",
       "      <td>1.503557</td>\n",
       "      <td>0.491480</td>\n",
       "      <td>0.472531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.590000</td>\n",
       "      <td>12.410000</td>\n",
       "      <td>0.808100</td>\n",
       "      <td>4.899000</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.765100</td>\n",
       "      <td>4.519000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.270000</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>0.856900</td>\n",
       "      <td>5.262250</td>\n",
       "      <td>2.944000</td>\n",
       "      <td>2.561500</td>\n",
       "      <td>5.045000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.355000</td>\n",
       "      <td>14.320000</td>\n",
       "      <td>0.873450</td>\n",
       "      <td>5.523500</td>\n",
       "      <td>3.237000</td>\n",
       "      <td>3.599000</td>\n",
       "      <td>5.223000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.305000</td>\n",
       "      <td>15.715000</td>\n",
       "      <td>0.887775</td>\n",
       "      <td>5.979750</td>\n",
       "      <td>3.561750</td>\n",
       "      <td>4.768750</td>\n",
       "      <td>5.877000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.180000</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>0.918300</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>4.033000</td>\n",
       "      <td>8.456000</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             area  perimeterÂ   compactness  length of kernel  width of kernel  \\\n",
       "count  210.000000  210.000000   210.000000        210.000000       210.000000   \n",
       "mean    14.847524   14.559286     0.870999          5.628533         3.258605   \n",
       "std      2.909699    1.305959     0.023629          0.443063         0.377714   \n",
       "min     10.590000   12.410000     0.808100          4.899000         2.630000   \n",
       "25%     12.270000   13.450000     0.856900          5.262250         2.944000   \n",
       "50%     14.355000   14.320000     0.873450          5.523500         3.237000   \n",
       "75%     17.305000   15.715000     0.887775          5.979750         3.561750   \n",
       "max     21.180000   17.250000     0.918300          6.675000         4.033000   \n",
       "\n",
       "       asymmetry coefficient  length of kernel groove        type  \n",
       "count             210.000000               210.000000  210.000000  \n",
       "mean                3.700201                 5.408071    0.333333  \n",
       "std                 1.503557                 0.491480    0.472531  \n",
       "min                 0.765100                 4.519000    0.000000  \n",
       "25%                 2.561500                 5.045000    0.000000  \n",
       "50%                 3.599000                 5.223000    0.000000  \n",
       "75%                 4.768750                 5.877000    1.000000  \n",
       "max                 8.456000                 6.550000    1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab5_df = pd.read_csv(\"./seeds_dataset_binary.csv\")\n",
    "lab5_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target attribute\n",
    "target_attribute_name = 'type'\n",
    "target = lab5_df[target_attribute_name]\n",
    "\n",
    "# predictor attributes\n",
    "predictors = lab5_df.drop(target_attribute_name, axis=1).values\n",
    "\n",
    "# scale all predictor values to the range [0, 1]\n",
    "# note the target attribute is already binary\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "predictors = min_max_scaler.fit_transform(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a training (80%) and test (20%) data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pepare independent stratified data sets for training and test of the final model\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(\n",
    "    predictors, target, test_size=0.20, shuffle=True, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Apply RFE with SVM for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True False  True  True]\n",
      "[5 2 3 1 4 1 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorSVM = svm.SVR(kernel=\"linear\")\n",
    "selectorSVM = RFE(estimatorSVM, 3)\n",
    "selectorSVM = selectorSVM.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorSVM.support_)\n",
    "print(selectorSVM.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Apply RFE with Logistic Regression for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False False  True  True]\n",
      "[3 4 1 5 2 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorLR = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "selectorLR = RFE(estimatorLR, 3)\n",
    "selectorLR = selectorLR.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorLR.support_)\n",
    "print(selectorLR.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Evaluate on the Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selectors to prepare training data sets only with the selected features\n",
    "\n",
    "__Note:__ The same selectors are applied to the test data set. However, it is important that the test data set was not used by (it's invisible to) the selectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_SVMselected = selectorSVM.transform(predictors_train)\n",
    "predictors_test_SVMselected = selectorSVM.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_LRselected = selectorLR.transform(predictors_train)\n",
    "predictors_test_LRselected = selectorLR.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate SVM classifiers with both the selected features and all features \n",
    "\n",
    "Here we train three models:\n",
    "* model1 - with the features selected by SVM\n",
    "* model2 - with the features selected by Logistic Regression\n",
    "* model3 - with all features (i.e. without feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = classifier.fit(predictors_train_SVMselected, target_train)\n",
    "model1.score(predictors_test_SVMselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = classifier.fit(predictors_train_LRselected, target_train)\n",
    "model2.score(predictors_test_LRselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cathalc/.pyenv/versions/3.5.6/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9047619047619048"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = classifier.fit(predictors_train, target_train)\n",
    "model3.score(predictors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Conclusion\n",
    "\n",
    "The results above, give evidence that model1 is most accurate.\n",
    "\n",
    "However, when you execute this code again, it is very likely to get different results.\n",
    "\n",
    "To get more accurate results, accounting for the variance in the results, it is better to run the whole experiment multiple times and measure the variance in the results. Then pick the model that gives better results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
