{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSc in AI - CE6002 & CS5062\n",
    "\n",
    "\n",
    "# E-tivity 5: Higher Dimensions\n",
    "\n",
    "# CS5062 -Feature Selection - Tasks 1, 2 and 3\n",
    "\n",
    "## Student Name: Mark Murnane\n",
    "## Student ID: 18195326\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing #needed for scaling attributes to the nterval [0,1]\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following will suppress warnings from sci-kit learn on changes to default values in future releases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't want FutureWarnings from scikit-learn\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the dataset for training and evaluation\n",
    "Feel free to apply any other pre-processing technique at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df = pd.read_csv(\"./winequality_red.csv\")\n",
    "wine_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a quick view of the data\n",
    "wine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target attribute\n",
    "target_attribute_name = 'quality'\n",
    "target = wine_df[target_attribute_name]\n",
    "\n",
    "# predictor attributes\n",
    "predictors = wine_df.drop(target_attribute_name, axis=1).values\n",
    "\n",
    "# scale all predictor values to the range [0, 1]\n",
    "# note the target attribute is already binary\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "predictors = min_max_scaler.fit_transform(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Distribution\n",
    "\n",
    "The initial testing in Task 1 below demonstrates that the models generated have difficulty correctly predicting the target class (with scores of < 60%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22f1cdffef0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the vast majority of the target values (> 75%) are grouped around the values 5 and 6, it is difficult for the model to discriminate between some of the target values.  \n",
    "\n",
    "Depending on later tasks, it may be useful to reclassify the quality as either \"Poor\", \"Normal\", \"Improved\". This would improve the accuracy of the models by creating larger target \"groups\" on which to train.  Nik has pointed out that accuracy is not the goal, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into a training (80%) and test (20%) data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pepare independent stratified data sets for training and test of the final model\n",
    "predictors_train, predictors_test, target_train, target_test = train_test_split(\n",
    "    predictors, target, test_size=0.20, shuffle=True, stratify=target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Apply RFE with SVM for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False False False False  True  True]\n",
      "[4 1 9 5 3 8 2 6 7 1 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorSVM = svm.SVR(kernel=\"linear\")\n",
    "selectorSVM = RFE(estimatorSVM, 3)\n",
    "selectorSVM = selectorSVM.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorSVM.support_)\n",
    "print(selectorSVM.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that RFE with SVM has selected the features _volatile acidity_, _sulphates_ and _alcohol_ as the 3 best features for predicting the target classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Apply RFE with Logistic Regression for selecting the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False False  True False False False  True]\n",
      "[5 1 4 9 7 6 1 3 8 2 1]\n"
     ]
    }
   ],
   "source": [
    "# create a base classifier used to evaluate a subset of attributes\n",
    "estimatorLR = LogisticRegression()\n",
    "# create the RFE model and select 3 attributes\n",
    "selectorLR = RFE(estimatorLR, 3)\n",
    "selectorLR = selectorLR.fit(predictors_train, target_train)\n",
    "# summarize the selection of the attributes\n",
    "print(selectorLR.support_)\n",
    "print(selectorLR.ranking_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above shows that RFE with Logistic Regression has selected the features _volatile acidity_, _total sulfur dioxide_ and _alcohol_ as the 3 best features for predicting the target classes.\n",
    "\n",
    "The change from SVM is the swap of _sulphates_ for _total sulfur dioxide_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Evaluate on the Test Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the selectors to prepare training data sets only with the selected features\n",
    "\n",
    "__Note:__ The same selectors are applied to the test data set. However, it is important that the test data set was not used by (it's invisible to) the selectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_SVMselected = selectorSVM.transform(predictors_train)\n",
    "predictors_test_SVMselected = selectorSVM.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors_train_LRselected = selectorLR.transform(predictors_train)\n",
    "predictors_test_LRselected = selectorLR.transform(predictors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate SVM classifiers with both the selected features and all features \n",
    "\n",
    "Here we train three models:\n",
    "* model1 - with the features selected by SVM\n",
    "* model2 - with the features selected by Logistic Regression\n",
    "* model3 - with all features (i.e. without feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.559375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = classifier.fit(predictors_train_SVMselected, target_train)\n",
    "model1.score(predictors_test_SVMselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = classifier.fit(predictors_train_LRselected, target_train)\n",
    "model2.score(predictors_test_LRselected, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.559375"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = classifier.fit(predictors_train, target_train)\n",
    "model3.score(predictors_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Conclusion\n",
    "\n",
    "In this initial run the classifier results show that the classifier with all values is actually the best.  The margin to the Logistic Regression feature selection is small, however, so this may not be indicative.\n",
    "\n",
    "The difference to the model train with SVM's chosen features is greater.  As they both chose _volatile acidity_ and _alchohol_ as key features, this suggests that _total sulfur dioxide_ is a better predictive feature than _sulphates_.\n",
    "\n",
    "Additionally the similarity of the accuracies across all three models suggests that _volatile acidity_ and _alcohol_ are dominant features in predicting the target _quality_.  The remaining features may add some additional accuracy, but do not make a significant addition to a model's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "\n",
    "# Task 2\n",
    "\n",
    "\n",
    "Repeat the experiment from Task 1 in a loop with different training/test stratified splits.\n",
    "\n",
    "For this task the use of Scikit's `StratifiedKFold` seems to tbe the most appropriate way to split the data.\n",
    "\n",
    "A hold out set can also be used for testing the optimal model suggested by the K-Fold testing.  As we've already split the data above we can hold on to that split data in the form of `target_train` and `target_test`.\n",
    "\n",
    "## Loop evaluation for feature selection\n",
    "\n",
    "\n",
    "#### TODO\n",
    "Fix target_train type of Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START]\tBegin processing fold 0 ... \n",
      "[END]\tFinished processing fold 0\n",
      "\n",
      "[START]\tBegin processing fold 1 ... \n",
      "[END]\tFinished processing fold 1\n",
      "\n",
      "[START]\tBegin processing fold 2 ... \n",
      "[END]\tFinished processing fold 2\n",
      "\n",
      "[START]\tBegin processing fold 3 ... \n",
      "[END]\tFinished processing fold 3\n",
      "\n",
      "[START]\tBegin processing fold 4 ... \n",
      "[END]\tFinished processing fold 4\n",
      "\n",
      "Completed StratifiedKFold processing\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 10 folds for training.  Have the data shuffled before the split\n",
    "# Shuffling will also be done by train_test_split so may not be required, but extra shuffle won't hurt\n",
    "\n",
    "SPLITS = 5\n",
    "\n",
    "strat_fold = StratifiedKFold(n_splits=SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies_SVM = np.zeros(SPLITS)\n",
    "accuracies_LR = np.zeros(SPLITS)\n",
    "accuracies_ALL = np.zeros(SPLITS)\n",
    "\n",
    "# Keep track of fold we're in, just in case\n",
    "for fold, (train_idx, validation_idx) in enumerate(strat_fold.split(predictors_train, target_train.values)):\n",
    "    print(f\"[START]\\tBegin processing fold {fold} ... \")\n",
    "   \n",
    "    # First of all, split this folds data into training and test sets\n",
    "    fold_X_train, fold_X_val = predictors_train[train_idx], predictors_train[validation_idx]\n",
    "    fold_y_train, fold_y_val = target_train.values[train_idx], target_train.values[validation_idx] \n",
    "\n",
    "    # Now that the data is split we can run feature selection as the validation set remains independent of the feature selection\n",
    "    # The validation set is also transformed based on the training set, but has not influenced that transform\n",
    "    # As we're repeating the Task 1 experiement, we can re-use the selector objects from above\n",
    "    selectorSVM = selectorSVM.fit(fold_X_train, fold_y_train)  \n",
    "    fold_train_SVM_predictors = selectorSVM.transform(fold_X_train)\n",
    "    fold_val_SVM_predictors = selectorSVM.transform(fold_X_val)\n",
    "    \n",
    "    # Repeat for Logistic Regression\n",
    "    selectorLR = selectorLR.fit(fold_X_train, fold_y_train)\n",
    "    fold_train_LR_predictors = selectorLR.transform(fold_X_train)\n",
    "    fold_val_LR_predictors = selectorLR.transform(fold_X_val)\n",
    "    \n",
    "          \n",
    "    # Evaluate the models for this split and store the results\n",
    "    fold_SVM = classifier.fit(fold_train_SVM_predictors, fold_y_train)\n",
    "    accuracies_SVM[fold] = fold_SVM.score(fold_val_SVM_predictors, fold_y_val)\n",
    "    \n",
    "    fold_LR = classifier.fit(fold_train_LR_predictors, fold_y_train)\n",
    "    accuracies_LR[fold] = fold_LR.score(fold_val_LR_predictors, fold_y_val)\n",
    "    \n",
    "    fold_ALL = classifier.fit(fold_X_train, fold_y_train)\n",
    "    accuracies_ALL[fold] = fold_ALL.score(fold_X_val, fold_y_val)\n",
    "    \n",
    "    print(f\"[END]\\tFinished processing fold {fold}\\n\")\n",
    "    \n",
    "print(\"Completed StratifiedKFold processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy values for SVM feature selection: [0.53696498 0.57976654 0.54296875 0.57254902 0.56692913]\n",
      "\n",
      "Accuracy values for LR feature selection: [0.53696498 0.58754864 0.55859375 0.60392157 0.59448819]\n",
      "\n",
      "Accuracy values for no feature selection: [0.52918288 0.58365759 0.55859375 0.58039216 0.57086614]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy values for SVM feature selection: {accuracies_SVM}\\n\")\n",
    "print(f\"Accuracy values for LR feature selection: {accuracies_LR}\\n\")\n",
    "print(f\"Accuracy values for no feature selection: {accuracies_ALL}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22f1d3bc630>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies_df = pd.DataFrame({'SVM':accuracies_SVM, 'LR':accuracies_LR, 'All':accuracies_ALL})\n",
    "accuracies_df.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The box plot shows that the Logistic Regression selected features outperformed the SVM-selected features as well as the models with no features selected.  It had not only the highest results, but the range of results was higher than the other models. \n",
    "\n",
    "The results stands in contrast to Task 1 where the _All features_ model was slightly better.  This experiment appears to confirm the suspicion that the results for _All_ in Task 1 was \"lucky\" rather than something specific in the feature set.  The improved results for LR in Task 2 confirm that the extra features in _All_ add no benefit in training the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
